
Command: mnist_softmax_dg.py
step 0, training accuracy 0.06, test accuracy 0.1031
step 100, training accuracy 0.74, test accuracy 0.7895
step 200, training accuracy 0.86, test accuracy 0.8829
step 300, training accuracy 0.88, test accuracy 0.9139
step 400, training accuracy 0.9, test accuracy 0.921
step 500, training accuracy 0.88, test accuracy 0.9258
step 600, training accuracy 0.92, test accuracy 0.9408
step 700, training accuracy 0.9, test accuracy 0.9424
step 800, training accuracy 0.94, test accuracy 0.9504
step 900, training accuracy 0.96, test accuracy 0.953
step 1000, training accuracy 0.92, test accuracy 0.9506
step 1100, training accuracy 0.96, test accuracy 0.9579
step 1200, training accuracy 0.98, test accuracy 0.9592
step 1300, training accuracy 0.96, test accuracy 0.9597
step 1400, training accuracy 0.96, test accuracy 0.9629
step 1500, training accuracy 0.96, test accuracy 0.9641
step 1600, training accuracy 1, test accuracy 0.9637
step 1700, training accuracy 0.96, test accuracy 0.9686
step 1800, training accuracy 1, test accuracy 0.97
step 1900, training accuracy 0.98, test accuracy 0.9674
step 2000, training accuracy 0.96, test accuracy 0.9647
test accuracy 0.9647

Command: mnist_softmax_dg.py --drop_grads_prob=1.0
step 0, training accuracy 0.06, test accuracy 0.0832
step 100, training accuracy 0.12, test accuracy 0.0832
step 200, training accuracy 0.12, test accuracy 0.0832
step 300, training accuracy 0.18, test accuracy 0.0832
step 400, training accuracy 0.06, test accuracy 0.0832
step 500, training accuracy 0.04, test accuracy 0.0832
step 600, training accuracy 0.14, test accuracy 0.0832
step 700, training accuracy 0.04, test accuracy 0.0832
step 800, training accuracy 0.06, test accuracy 0.0832
step 900, training accuracy 0.1, test accuracy 0.0832
step 1000, training accuracy 0.02, test accuracy 0.0832
step 1100, training accuracy 0.08, test accuracy 0.0832
step 1200, training accuracy 0.08, test accuracy 0.0832
step 1300, training accuracy 0.16, test accuracy 0.0832
step 1400, training accuracy 0.02, test accuracy 0.0832
step 1500, training accuracy 0.1, test accuracy 0.0832
step 1600, training accuracy 0.1, test accuracy 0.0832
step 1700, training accuracy 0.08, test accuracy 0.0832
step 1800, training accuracy 0.1, test accuracy 0.0832
step 1900, training accuracy 0.14, test accuracy 0.0832
step 2000, training accuracy 0.1, test accuracy 0.0832
test accuracy 0.0832

Command: mnist_softmax_dg.py --drop_grads_prob=0.0
step 0, training accuracy 0.04, test accuracy 0.1064
step 100, training accuracy 0.86, test accuracy 0.8546
step 200, training accuracy 0.9, test accuracy 0.9139
step 300, training accuracy 0.88, test accuracy 0.9325
step 400, training accuracy 0.88, test accuracy 0.9423
step 500, training accuracy 0.94, test accuracy 0.952
step 600, training accuracy 0.94, test accuracy 0.9521
step 700, training accuracy 0.96, test accuracy 0.9586
step 800, training accuracy 0.96, test accuracy 0.961
step 900, training accuracy 0.98, test accuracy 0.9657
step 1000, training accuracy 0.98, test accuracy 0.9644
step 1100, training accuracy 0.98, test accuracy 0.9684
step 1200, training accuracy 0.96, test accuracy 0.971
step 1300, training accuracy 0.94, test accuracy 0.9713
step 1400, training accuracy 0.98, test accuracy 0.9705
step 1500, training accuracy 1, test accuracy 0.9721
step 1600, training accuracy 0.98, test accuracy 0.9745
step 1700, training accuracy 0.96, test accuracy 0.9746
step 1800, training accuracy 0.96, test accuracy 0.9777
step 1900, training accuracy 1, test accuracy 0.9751
step 2000, training accuracy 1, test accuracy 0.9771
test accuracy 0.9777
